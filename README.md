# ğŸ” Code Snippet Generation using Fine-Tuned T5

This project is a code snippet generation system built using a fine-tuned [T5-small](https://huggingface.co/t5-small) model. It takes natural language programming queries and returns relevant code snippets. A simple web interface is built using Streamlit.

---

## ğŸ“Œ Features

- Fine-tuned T5 on natural language â†’ code mapping
- Streamlit-based frontend for live query testing
- Easily extendable to other languages or domains

---

## ğŸ“‚ Directory Structure

â”œâ”€â”€ app/
â”‚ â””â”€â”€ streamlit_app.py # Streamlit frontend
â”œâ”€â”€ src/
â”‚ â””â”€â”€ train_t5.py # Model training script
â”œâ”€â”€ data/
â”‚ â””â”€â”€ extended_programming_code_snippets.csv # Dataset
â”œâ”€â”€ t5_finetuned_model/ # Fine-tuned model (excluded from Git)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## ğŸ“Š Dataset

File: `data/extended_programming_code_snippets.csv`  
The dataset consists of three columns:

| Column        | Description                             |
|---------------|-----------------------------------------|
| `Query`       | Natural language programming query      |
| `Code_Snippet`| Expected output code                    |
| `Tags`        | (Optional) Tags like language/domain    |

---

## ğŸ‹ï¸â€â™‚ï¸ Training the Model

1. Prepare your dataset at `./data/extended_programming_code_snippets.csv`
2. Run the training script:

```bash
python src/train_t5.py


This will save the fine-tuned model and tokenizer to:
./t5_finetuned_model/

ğŸŒ Running the Streamlit App
After training, you can run the frontend locally:

1. Install dependencies

pip install -r requirements.txt

 Start the app

streamlit run app/streamlit_app.py

Sample Output
Query: how to sort a list in python

my_list = [3, 1, 4, 1, 5, 9]
my_list.sort()
print(my_list)


ğŸ§°Tech Stack
Hugging Face Transformers

PyTorch

Streamlit

Google Colab (for training)

ğŸ“Œ Notes
The model (t5_finetuned_model/) is excluded from the repo to avoid large file uploads. You should train or manually place it locally.

You can upload the trained model to Hugging Face Hub or Google Drive for deployment.


ğŸ“„ License
MIT License Â© 2025 Vishal Meena

ğŸ‘¨â€ğŸ’» Author
Vishal Meena
IIT Kharagpur
ğŸ”— [LinkedIn](https://linkedin.com/in/vishalmeenaiit)



